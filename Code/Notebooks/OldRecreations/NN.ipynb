{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNets\n",
    "This notebook will contain my attempts using NeuralNetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stone\\Miniconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, SGD, Adadelta\n",
    "import keras.backend as K\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, make_scorer\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eBoss Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the eboss data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_eBoss = pd.read_csv(\"../../../Data/Astronomy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking out the id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_data = raw_data_eBoss.iloc[:, 1:].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating the X, and Y variables, and doing needed preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainable_data.iloc[:, :-1].copy(deep=True)\n",
    "Y = trainable_data.iloc[:, -1:].copy(deep=True)\n",
    "X = X.apply(pd.to_numeric, args={'errors': 'coerce'})\n",
    "X = X.fillna('0')\n",
    "Y = Y.Hits.map({'bad': 0, 'good': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(ss.fit_transform(X), columns=X.columns)\n",
    "X = df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the model starting with a simple 3 layer model with 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_no(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, pos_label=0)\n",
    "def recall_no(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr=.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(96, input_dim=96, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "metrics=[precision_no, precision_score, recall_no, recall_score, accuracy_score,  f1_score, roc_auc_score]\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "cvscores = defaultdict(list)\n",
    "for train, test in kfold.split(X.values, Y.values):\n",
    "    model = create_model(lr=.001)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X.values[train], Y.values[train], epochs=100, batch_size=8, verbose=0)\n",
    "    \n",
    "    # evaluate the model\n",
    "    #scores = model.evaluate(X.values[test], Y.values[test], verbose=0)\n",
    "    \n",
    "    y_preds = model.predict_classes(X.values[test])\n",
    "    y_true = Y.values[test]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        cvscores[metric.__name__].append(metric(y_true, y_preds))\n",
    "        \n",
    "    cvscores['roc_auc_real'].append(roc_auc_score(y_true, model.predict(X.values[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_real :  0.9687925170068027\n",
      "precision_no :  0.9325396825396826\n",
      "precision_score :  0.9379871577697665\n",
      "recall_no :  0.7807539682539683\n",
      "recall_score :  0.975909090909091\n",
      "accuracy_score :  0.9326354679802955\n",
      "f1_score :  0.9560583620401619\n",
      "roc_auc_score :  0.8783315295815296\n"
     ]
    }
   ],
   "source": [
    "for k,v in cvscores.items():\n",
    "    print(k, \": \", np.mean(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manga Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_Manga = pd.read_csv(\"../../../Data/Astronomy20000_Original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating the X, and Y variables, and doing needed preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data_Manga.iloc[:, 1:-1].copy(deep=True)\n",
    "Y = raw_data_Manga.iloc[:, [-1]].copy(deep=True)\n",
    "X = X.fillna('0')\n",
    "Y = Y.Hits.map({'bad': 0, 'good': 1})\n",
    "X = X.iloc[:, np.r_[2:14, 26:len(X.columns)]].copy(deep=True)\n",
    "ss = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(ss.fit_transform(X), columns=X.columns)\n",
    "X = df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr=.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(108, input_dim=108, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = create_model(lr=.001)\n",
    "mdl.fit(X.values, Y.values, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold: 1!\n",
      "Starting Fold: 2!\n",
      "Starting Fold: 3!\n",
      "Starting Fold: 4!\n",
      "Starting Fold: 5!\n",
      "Starting Fold: 6!\n",
      "Starting Fold: 7!\n",
      "Starting Fold: 8!\n",
      "Starting Fold: 9!\n",
      "Starting Fold: 10!\n"
     ]
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, precision_no, recall_score, recall_no, f1_score, roc_auc_score]\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "cvscores = defaultdict(list)\n",
    "ix = 1\n",
    "for train, test in kfold.split(X.values, Y.values):\n",
    "    print(\"Starting Fold: {}!\".format(ix))\n",
    "    ix += 1\n",
    "    model = create_model()\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X.values[train], Y.values[train], epochs=100, batch_size=128, verbose=0)\n",
    "    \n",
    "    # evaluate the model\n",
    "    #scores = model.evaluate(X.values[test], Y.values[test], verbose=0)\n",
    "    \n",
    "    y_preds = model.predict_classes(X.values[test])\n",
    "    y_true = Y.values[test]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        cvscores[metric.__name__].append(metric(y_true, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score :  0.8636025548525549\n",
      "precision_score :  0.7962976241250492\n",
      "precision_no :  0.8811265490050605\n",
      "recall_score :  0.6151358123424362\n",
      "recall_no :  0.9460719784443532\n",
      "f1_score :  0.6917783117492088\n",
      "roc_auc_score :  0.7806038953933946\n"
     ]
    }
   ],
   "source": [
    "for k,v in cvscores.items():\n",
    "    print(k, \": \", np.mean(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
